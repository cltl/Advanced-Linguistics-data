{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring DFN annotated data structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces the annotated data from the Dutch FrameNet annotation tool. We will analyze the dictionary structure of one annotated reference text. Once you are familiarized with the richness of this structure, you can write code to iterate over your corpus, extract the data you want to analyze and restructure or visuzalize them in any way you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us import some packages first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import glob\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your corpus, we have a json file for each annotated reference text. We will now open one json file from the Dutch Utrecht_shooting corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Utrecht_shooting/annotated_data/'Agenten zagen bij een slachtoffer dat de telefoon maar bleef afgaan. Dat is heel moeilijk’.json\", 'r') as infile:\n",
    "    json_dict = json.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each json file has one key, which is the title of the annotated reference text. Its value consists of the following keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([\"fe's without links\", 'frames/links', 'historical distance', \"implicated fe's\", 'raw text', 'subevents'])\n"
     ]
    }
   ],
   "source": [
    "json_dict_title = json_dict[\"'Agenten zagen bij een slachtoffer dat de telefoon maar bleef afgaan. Dat is heel moeilijk’\"]\n",
    "print(json_dict_title.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will discuss the content and structure of each key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Raw text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of 'raw text' displays exactly what it stands for: the raw unannotated text of the document. This can be convenient when you want to perform some qualitative analysis or simply get a good picture of what has been annotated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'Agenten zagen bij een slachtoffer dat de telefoon maar bleef afgaan. Dat is heel moeilijk’ Aanslag UtrechtAl direct heeft hij het gevoel dat er iets niet pluis is. Dit is geen gewone liquidatie, denkt Rob van Bree (41) als hij in de ochtend van 18 maart hoort dat er is geschoten in een tram op het 24 Oktoberplein in Utrecht. Het hoofd operaties van de politie Midden-Nederland pakt meteen de telefoon en belt met de recherchechef en algemeen commandant van het crisisteam. Direct daarna wordt hij zelf gebeld. ,,De meldkamer. Ze werden daar overspoeld met telefoontjes.’’ Dan is duidelijk dat zijn gevoel klopt. ,,Het is echt groot.” Het begin van een dag die z’n weerga niet kent.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(json_dict_title[\"raw text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Historical distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of 'historical distance' displays the number of days between the event date and the publication date of the text. The temporal distance range of your corpus can be used as a variable in your analysis to see if your observed patterns change over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This document is written 12 days after the main event.\n"
     ]
    }
   ],
   "source": [
    "print(\"This document is written\",json_dict_title['historical distance'], \"days after the main event.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Frames/links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value is a dictionary containing information about text mentions that are annotated with both a link to a structured entry and with frame information. Its keys are identifiers encoding structured entries. In order to interpret this identifier, we can make use of *structured_data.json* , which contains a mapping from identifiers to labels. We will take one identifier and examine the information linked to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Q1632409367599', 'Q62090804', 'Q803'])\n",
      "\n",
      "Q62090804 maps to {'sem:incidentID': '2019 Utrecht shooting'}\n",
      "\n",
      "dict_keys(['t19', 't37'])\n"
     ]
    }
   ],
   "source": [
    "print(json_dict_title['frames/links'].keys())\n",
    "\n",
    "with open(\"Utrecht_shooting/structured_data.json\", 'r') as infile:\n",
    "    structured_data_dict = json.load(infile)\n",
    "\n",
    "print()\n",
    "print(\"Q62090804 maps to\", structured_data_dict[\"Q62090804\"])\n",
    "print()\n",
    "print(json_dict_title['frames/links']['Q62090804'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be links of in-text mentions to three different structured entries. Identifier Q62090804 maps to the main event itself. In our dictionary, each identifier has a nested dictionary with tokens as keys. These tokens encode words that were tagged by the annotators in the raw text. Each token has its own nested dictionary. This dictionary consists of all linguistic and grounding information that you need. We will take a look at the dictionary of one token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'POS': 'NOUN',\n",
      " 'article': {'definite': None, 'lemma': None},\n",
      " 'frame': 'Attack',\n",
      " 'frame elements': ['Catastrophe@Undesirable_event',\n",
      "                    'Killing@Cause',\n",
      "                    'Contacting@Topic',\n",
      "                    'Contacting@Topic'],\n",
      " 'lemma': 'aanslag',\n",
      " 'reftype': 'evoke',\n",
      " 'sentence': '2',\n",
      " 'target phrase': 'dat zijn heel moeilijk ’ aanslag utrechtal'}\n"
     ]
    }
   ],
   "source": [
    "#these are the layers of nesting:\n",
    "pprint.pprint(json_dict[\"'Agenten zagen bij een slachtoffer dat de telefoon maar bleef afgaan. Dat is heel moeilijk’\"] #document title\n",
    "                      ['frames/links'] #information type\n",
    "                      ['Q62090804'] #structured entry\n",
    "                      ['t19']) #token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dictionary contains all linguistic information in regards to the selected token. We will go over all the keys:\n",
    "\n",
    "* **lemma** = the lemmatized linguistic form of the tagged word in the raw text. In this case, this is the word 'aanslag' ('attack'). Hence, the annotators have linked this word in the text to the respective identifier in the structured data.\n",
    "\n",
    "* **POS** = the POS of the token, in this case a noun. \n",
    "\n",
    "* **article** = any information about articles (definiteness and lemma) are provided in a dictionary. This can be useful if you want to look at the use of definiteness as a function of common ground. In this case, since 'aanslag' is not modified with an article, the values in this dictionary are None.\n",
    "\n",
    "* **sentence** = the number of the sentence in which this word occurs. This word appears in the second sentence, which is probably in the beginning of the text.\n",
    "\n",
    "* **target phrase** = the syntactic phrase of which the word is the semantic head. This was automatically reconstructed and all words are lemmatized, so it is sometimes far from perfect. But you can always look into the raw layer for the linguistic context. If the word is only annotated with a frame, then this key is absent.\n",
    "\n",
    "* **reftype** = whether the frame and word both refer to the same structured entry. In this case it does. But this has been wrongly annotated way too often, so unfortunately you cannot make use of it.\n",
    "\n",
    "* **frame** = if the annotator has annotated the word with a frame, you can find it here. In this case, 'aanslag' has been annotated with Attack. \n",
    "\n",
    "* **frame elements** = a list of frame elements that the word has been annotated with. It can exhibit frame elements of the frame that is evoked by the same word, i.e., an incorporated frame element, but also frame elements belonging to frames evoked in different sentences (as a product of discourse annotation). Each frame element's form is inherently constructed as frame@frame_element. In this case, all frame elements belong to frames evoked in different sentences.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Subevents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reference text usually uses only a handful of general references to the main event. Those are both frame-annotated and linked to the incidentID in the structured data and can thus be found under the key 'frames/coreferences' (see above). The remainder of the eventive predicates in the text are not linked to structured data and only frame-annotated if they are subevents of the main event. Predicates are considered subevents if they play an important part in shaping the narrative of the event. They can be:\n",
    "\n",
    "* **rising** events: events that are a direct cause of the main event. They occur beforehand.\n",
    "* events **entailed** by the main event\n",
    "* **falling** events: events that are directly caused by the main event. They occur in the aftermath.\n",
    "\n",
    "Predicates that are frame-annotated due to their nature of expressing subevents are found under this key. The dictionary per predicate is structured in similar fashion to the dictionaries for the predicates under 'frames/coreferences'. Now we will have look at the tokens grouped under this header, and pick one to examine more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['t104.c0', 't109', 't58', 't83', 't86.c0', 't92.c0', 't92.c1', 't99'])\n",
      "\n",
      "{'POS': 'ADJ',\n",
      " 'article': {'definite': None, 'lemma': None},\n",
      " 'compound': 'meldkamer',\n",
      " 'frame': 'Reporting',\n",
      " 'frame elements': None,\n",
      " 'function': 'modifier',\n",
      " 'lemma': 'meld',\n",
      " 'reftype': 'type',\n",
      " 'sentence': '7'}\n"
     ]
    }
   ],
   "source": [
    "print(json_dict_title['subevents'].keys())\n",
    "\n",
    "#these are the layers of nesting:\n",
    "print()\n",
    "pprint.pprint(json_dict[\"'Agenten zagen bij een slachtoffer dat de telefoon maar bleef afgaan. Dat is heel moeilijk’\"] #document title\n",
    "                      ['subevents'] #information type\n",
    "                      ['t104.c0']) #token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This token encodes the word 'meld' ('report'). This is a lexeme that is part of a Dutch compound. This compound was split in the tool and its lexemes were seperately annotated. 'meld' was not linked to structured data, otherwise it would be grouped under 'frames/coreferences'. When an annotated word is part of a compound, its token has a suffix. In this case, the suffix is '.c0'. Given the compounding nature of the word, the following keys have been added to the dictionary:\n",
    "\n",
    "* **compound**: the lemma of the compound that the annotated lexeme is a part of. In this case, the compound is 'meldkamer' ('control room'). Note that 'lemma' only provides the tagged lexeme 'meld'.\n",
    "* **function**: the syntactic function of the lexeme in the compound. Compounds usually consist of a head and a modifier. In this case, 'meld' is the modifier of 'kamer'.\n",
    "\n",
    "Note: when the annotators split a Dutch compound, they annotated both parts with any frame or frame element. Exceptionally, the status of the potential frame element was disregarded, which means that a subpart of a compound is also annotated with a frame element if the frame element is peripheral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Frame elements without links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The annotators had to annotate all core frame elements of each annotate frame, disregarding whether the mentions expressing the frame element is linked to the structured data or not. All mentions of frame elements without a link to structured data can be found under \"fe's without coreference\". Let us have a look at the annotated tokens under this key and pick one token for further examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['t104.c1', 't111', 't70', 't86.c1', 't97'])\n",
      "\n",
      "{'POS': 'NOUN',\n",
      " 'article': {'definite': None, 'lemma': None},\n",
      " 'compound': 'meldkamer',\n",
      " 'frame elements': ['Mass_motion@Goal', 'Reporting@Place'],\n",
      " 'function': 'head',\n",
      " 'lemma': 'kamer',\n",
      " 'sentence': '7',\n",
      " 'target phrase': 'meldkamer'}\n"
     ]
    }
   ],
   "source": [
    "print(json_dict_title[\"fe's without links\"].keys())\n",
    "\n",
    "#these are the layers of nesting:\n",
    "print()\n",
    "pprint.pprint(json_dict[\"'Agenten zagen bij een slachtoffer dat de telefoon maar bleef afgaan. Dat is heel moeilijk’\"] #document title\n",
    "                      [\"fe's without links\"] #information type\n",
    "                      ['t104.c1']) #token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the structure of the dictionary belonging to 'kamer' ('room') is similar to that of 'frames/coreference' and 'subevents'. 'kamer' here is part of the compound, 'meldkamer'. Since 'melden' evokes a frame that references a subevent of the main event, its token t104.c0 is grouped under 'Subevents'. But 'kamer' only expresses frame elements, and is thus placed under \"fe's without coreference\". It is expressing Place of the Reporting frame evoked by 'meld'. Furthermore, we see that it expresses Goal of a Mass_motion frame, evoked in some other sentence. Notice that there is no key for a frame. If 'kamer' would evoke a frame, it would have been put under 'subevents'. Thus, \"fe's without coreference\" is reserved for words annotated with frame elements but not frames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Implicated frame elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the DFN annotation tool, the annotators performed frame annotation on discourse level. This means that if they could not find a core frame element within the sentence of its frame-evoking lexical unit, they could look for it across sentence boundaries. If they could not find the frame element in discourse, they clicked the \"unexpressed\" button, meaning that the frame element is completely absent. Since core frame elements must be present in order to cognitively process their frame, their absence from discourse means that they are pragmatically implicated. These frame elements are found in a list under \"implicated fe's\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Attack@Assailant',\n",
      " 'Killing@Killer',\n",
      " 'Killing@Instrument',\n",
      " 'Hit_target@Agent',\n",
      " 'Mass_motion@Area',\n",
      " 'Reporting@Informer',\n",
      " 'Reporting@Wrongdoer',\n",
      " 'Reporting@Authorities',\n",
      " 'Reporting@Behavior',\n",
      " 'Contacting@Communicator',\n",
      " 'Contacting@Address',\n",
      " 'Contacting@Communication',\n",
      " 'Contacting@Address',\n",
      " 'Contacting@Communication',\n",
      " 'Catastrophe@Undesirable_event',\n",
      " 'Catastrophe@Patient',\n",
      " 'Team@Members',\n",
      " 'Criminal_investigation@Incident',\n",
      " 'Criminal_investigation@Suspect']\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(json_dict_title[\"implicated fe's\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sum: we distinguish the following types of information in our json dictionary, grouped under the following keys:\n",
    "\n",
    "* **raw text** the raw unannotated text of the document\n",
    "* **historical distance** the distance in days from the document to the main event\n",
    "* **frames/links** linguistic information about the frame annotated references per structured entry that they are linked to\n",
    "* **subevents** linguistic annotation about frame annotated predicates referencing subevents instead of the main incident (no link to structured data).\n",
    "* **fe's without links** linguistic information about frame element annotations without links to structured data.\n",
    "* **implicated fe's** list of core frame elements that are absent from the reference text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you are familiar with the data structure, you can iterate over your corpus and extract and restructure the information you need for your analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titles in the Utrecht shooting corpus:\n",
      "\n",
      "Van Zanen: 'Twee verdachten vrij', politie ontkent\n",
      "Om kwart voor elf staat de tram stil, daarna heel Utrecht\n",
      "Vermoedelijke dader en twee andere verdachten aanslag Utrecht opgepakt\n",
      "Politie Utrecht houdt klopjacht op 37-jarige verdachte Gökmen Tanis\n",
      "Rutte: vlaggen op overheidsgebouwen vandaag halfstok\n",
      "'Agenten zagen bij een slachtoffer dat de telefoon maar bleef afgaan. Dat is heel moeilijk’\n",
      "Rechtbank verplicht verdachte van tramaanslag om naar zitting te komen\n",
      "Schietpartij 24 Oktoberplein\n",
      "Onderzoek naar schietincident vandaag verder\n",
      "Baudet (FvD) voert wél campagne en maakt CDA en VVD verwijten\n",
      "Verdachte Gökmen T. had schulden en zou woning kwijtraken\n",
      "Gökmen T. krijgt levenslang voor aanslag in Utrechtse tram\n",
      "Zwarte dag in Utrecht: dit gebeurde er op de dag van het schietincident\n",
      "Kleine bijdrage in kosten afscheid lieve Roos\n",
      "Duizenden mensen melden zich op ikbenveilig.nl\n",
      "Verplichte rechtsbijstand voor verdachte schietpartij Utrecht\n",
      "Extra alertheid bij moskeeën en stations in Brabant na schietpartij Utrecht\n",
      "Twentse agenten staken niet, maar helpen in Utrecht\n",
      "Gökmen T. schreef in briefje uit naam van Allah te handelen\n",
      "Aanhouding nieuwe verdachte schietincident Utrecht, heenzending twee verdachten\n",
      "Extra toezicht van politie bij stations en moskeeën\n",
      "Kamerbrief met nadere informatie naar aanleiding van de aanslag Utrecht 18 maart 2019\n",
      "Zoon van vierde slachtoffer aanslag Utrecht: 'Hij heeft zo veel geleden'\n",
      "Vierde slachtoffer schietpartij Utrechtse tram overleden\n",
      "1 miljoen zien start stille tocht Utrecht\n",
      "Gökmen Tanis bekent schietpartij in tram in Utrecht\n",
      "’Gestolen’ rode Renault Clio aangetroffen in Utrecht\n",
      "Voorarrest Gökmen T. in lopende zedenzaak\n",
      "Tramschutter Gökmen Tanis steekt gevangenisbewaker in het gezicht\n",
      "Rutte en Grapperhaus leggen bloemen bij aanslagplek in Utrecht\n",
      "Levenslange gevangenisstraf geëist voor aanslag in en rond Utrechtse tram\n",
      "Moskee in Zaandam beveiligd na schietpartij in Utrecht\n",
      "Advocaat tramschutter Gökmen T. overlegt met Orde over levenslange straf\n",
      "Liveblog teruglezen: Extra toezicht bij stations en moskeeën in Rotterdam na mogelijke aanslag Utrecht\n",
      "18 maart 2019: een heftige dag\n",
      "Gökmen T. bekent aanslag Utrecht, motief blijft onduidelijk\n",
      "Tramschutter Gökmen T. krijgt advocaat tegen zijn wil\n",
      "Geen trams en omleidingen busvervoer tijdens stille tocht Utrecht\n",
      "Verdachte schietincident 24-Oktoberplein Utrecht bekent en zegt alleen te hebben gehandeld\n",
      "Kamer nog niet in debat over schietpartij Utrecht\n",
      "Eerste reactie Rutte en Grapperhaus op schietpartij in Utrecht\n",
      "Aanslag Utrecht eist vierde leven\n"
     ]
    }
   ],
   "source": [
    "print(\"titles in the Utrecht shooting corpus:\")\n",
    "print()\n",
    "\n",
    "for filename in glob.glob(\"Utrecht_shooting/annotated_data/*\"):\n",
    "    with open(filename, 'r') as infile:\n",
    "        json_dict = json.load(infile)\n",
    "        for title, info_headers in json_dict.items():\n",
    "            print(title) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exercises below will help you to explore the corpus. The full code for the first exercise is given to help you on the way ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1:\n",
    "\n",
    "Use the identifier of the main event to extract all the frames and their lexical units, and rank them in frequency and percentage. Which frame has the largest variety of lexical units?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the main event is referenced 249 times\n",
      "\n",
      "sample of the set of frames used in reference:\n",
      "[('Attack', 'aanslag.NOUN'),\n",
      " ('Hit_target', 'schietincident.NOUN'),\n",
      " ('Catastrophe', 'schietincident.NOUN'),\n",
      " ('Attack', 'aanslag.NOUN'),\n",
      " ('Attack', 'aanslag.NOUN'),\n",
      " ('Attack', 'aanslag.NOUN'),\n",
      " ('Attack', 'aanslag.NOUN'),\n",
      " ('Attack', 'aanval.NOUN'),\n",
      " ('Terrorism', 'terroristisch.ADJ'),\n",
      " ('Attack', 'aanslag.NOUN')]\n"
     ]
    }
   ],
   "source": [
    "identifier = \"Q62090804\"\n",
    "frames_lus = []\n",
    "\n",
    "for filename in glob.glob(\"Utrecht_shooting/annotated_data/*\"): #iterate over the corpus\n",
    "    with open(filename, 'r') as infile:\n",
    "        json_dict = json.load(infile)\n",
    "\n",
    "    for title, values in json_dict.items():   #iterate over document\n",
    "        if identifier in values[\"frames/links\"]:   #check if identifier is present\n",
    "            for token, info_dict in values[\"frames/links\"][identifier].items():   #iterate over links\n",
    "                if info_dict['frame'] != None and 'lemma' in info_dict.keys():   #check if the annotation contains lemma and frame\n",
    "                    frame = info_dict['frame']\n",
    "                    if 'compound' in info_dict.keys():\n",
    "                        lemma_pos = info_dict['compound']+'.'+'NOUN'\n",
    "                    elif info_dict['POS'] == None:\n",
    "                        lemma_pos = info_dict['lemma']+'.X'\n",
    "                    else:\n",
    "                        lemma_pos = info_dict['lemma']+'.'+info_dict['POS']\n",
    "                    frames_lus.append((frame, lemma_pos))   #append tuple (frame, LU) to list\n",
    "\n",
    "print(f\"the main event is referenced {len(frames_lus)} times\")\n",
    "print()\n",
    "print(f\"sample of the set of frames used in reference:\")\n",
    "pprint.pprint(frames_lus[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking of most dominant frames in reference to the main event:\n",
      "\n",
      "freq ratio frame\n",
      "\n",
      "65 26.104 Attack\n",
      "49 19.679 Hit_target\n",
      "28 11.245 Catastrophe\n",
      "25 10.04 Participation\n",
      "18 7.229 Terrorism\n",
      "12 4.819 Committing_crime\n",
      "12 4.819 Killing\n",
      "7 2.811 Event\n",
      "7 2.811 Purpose\n",
      "6 2.41 Commitment\n"
     ]
    }
   ],
   "source": [
    "def sort_by_values_len(d):\n",
    "    \"\"\"sort dictionary by length of the values. Return list of dicts\"\"\"\n",
    "    dict_len= {key: len(value) for key, value in d.items()}\n",
    "    import operator\n",
    "    sorted_key_list = sorted(dict_len.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    sorted_dict = [{item[0]: d[item [0]]} for item in sorted_key_list]\n",
    "    return sorted_dict\n",
    "\n",
    "frames_dict = defaultdict(list)\n",
    "\n",
    "for frame_lu in frames_lus:\n",
    "    frame = frame_lu[0]\n",
    "    lu = frame_lu[1]\n",
    "    frames_dict[frame].append(lu)   #create a dictionary with frame as key and list of their annotated lexical units as value\n",
    "\n",
    "frames_sorted = sort_by_values_len(frames_dict)   #sort dictionary by frequency of annotated lexical units\n",
    "\n",
    "print(\"ranking of most dominant frames in reference to the main event:\")\n",
    "print()\n",
    "print('freq', 'ratio', 'frame')\n",
    "print()\n",
    "for frame_dict in frames_sorted[:10]:   #iterate over the top ranked frames\n",
    "    for frame, lus in frame_dict.items():\n",
    "        freq = len(lus)\n",
    "        percentage = round((freq*100)/len(frames_lus), 3)\n",
    "        print(freq, percentage, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ranking of frames with strongest variety of lexical units:\n",
      "\n",
      "5 Attack {'aanslagvanochtend.NOUN', 'tramaanslag.NOUN', 'aanslag.NOUN', 'terreuraanslag.NOUN', 'aanval.NOUN'}\n",
      "\n",
      "5 Killing {'dodelijk.ADJ', 'dood.ADJ', 'liquidatie.NOUN', 'moord.NOUN', 'moordpartij.NOUN'}\n",
      "\n",
      "4 Hit_target {'doodschieten.NOUN', 'schieten.VERB', 'schietpartij.NOUN', 'schietincident.NOUN'}\n",
      "\n",
      "4 Terrorism {'terroristisch.ADJ', 'terreur.NOUN', 'terreurdaad.NOUN', 'terreuraanslag.NOUN'}\n",
      "\n",
      "3 Catastrophe {'incident.NOUN', 'schietincident.NOUN', 'drama.NOUN'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "frames_dict = defaultdict(set)\n",
    "\n",
    "for frame_lu in frames_lus:\n",
    "    frame = frame_lu[0] \n",
    "    lu = frame_lu[1]\n",
    "    frames_dict[frame].add(lu) #create a dictionary with frame as key and a set of their unique lexical units as value\n",
    "\n",
    "frames_sorted = sort_by_values_len(frames_dict) #sort dictionary by frequency of unique lexical units\n",
    "\n",
    "print(\"ranking of frames with strongest variety of lexical units:\")\n",
    "print()\n",
    "for frame_d in frames_sorted[:5]:   #iterate over the top ranked frames\n",
    "    for frame, lus in frame_d.items():\n",
    "        print(len(lus), frame, set(lus))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Use the identifier of one of the participants in the main event to extract all the frame elements used to frame this person, and rank them on frequency and percentage. what frame elements are used most in reference to this person. Basically, you are applying the code of exercise 1 to frame elements linked to participants (instead of frames to events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Rank the lexical units in this corpus (both linked and not linked) with respect to their variety of frames. In other words, rank the words according to their polysemy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_lus = []\n",
    "\n",
    "for filename in glob.glob(\"Utrecht_shooting/annotated_data/*\"): #iterate over the corpus\n",
    "    with open(filename, 'r') as infile:\n",
    "        json_dict = json.load(infile)\n",
    "\n",
    "    for title, values in json_dict.items():   #iterate over document\n",
    "        for token, info_dict in values[\"frames/links\"].items(): #iterate over links\n",
    "            if info_dict['frame'] != None and 'lemma' in info_dict.keys():   #check if the annotation contains lemma and frame\n",
    "                frame = info_dict['frame']\n",
    "                if 'compound' in info_dict.keys():\n",
    "                    lemma_pos = info_dict['compound']+'.'+'NOUN'\n",
    "                elif info_dict['POS'] == None:\n",
    "                    lemma_pos = info_dict['lemma']+'.X'\n",
    "                else:\n",
    "                    lemma_pos = info_dict['lemma']+'.'+info_dict['POS']\n",
    "                frames_lus.append((frame, lemma_pos))   #append tuple (frame, LU) to list\n",
    "        for token, info_dict in values[\"subevents\"].items(): #iterate over subevents\n",
    "            #repeat the iteration above for subevents\n",
    "            #your code here\n",
    "\n",
    "lus_dict = defaultdict(set)\n",
    "\n",
    "for frame_lu in frames_lus:\n",
    "    frame = frame_lu[0]\n",
    "    lu = frame_lu[1]\n",
    "    lus_dict[lu].add(label)   \n",
    "\n",
    "lus_sorted = sort_by_values_len(lus_s)   #sort dictionary by frequency of their unique frames\n",
    "\n",
    "#your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Compile all frames in reference to subevents and compare them with the frames referencing the main incident."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
